{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP-2 Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oh La La... Data!\n",
    "\n",
    "\n",
    "* **Aymeryc COUSAERT** ------  *Padrón 105464 - Alumno regular de intercambio.*\n",
    "* **Mariana VINYOLAS**  ---------  *Alumna oyente.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3aDXdkY2bsU"
   },
   "source": [
    "<!-- ![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "<a id='section2'></a>\n",
    "\n",
    "<div style=\"border-bottom:3px solid #000;\"> \n",
    "<div align=\"left\"><h2>Step 2: Import de librerias </h2></div>\n",
    "<div align=\"right\">(return to <a href='#top1'><b>Top</b></a>)</div>\n",
    "</div> -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import scikitplot as skplt\n",
    "from scikitplot.metrics import plot_roc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Smnr3pgkKld_"
   },
   "source": [
    "<!-- ![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "<a id='section3'></a>\n",
    "\n",
    "<div style=\"border-bottom:3px solid #000;\"> \n",
    "<div align=\"left\"><h2>Step 3: Feature engineering</h2></div>\n",
    "<div align=\"right\">(return to <a href='#top1'><b>Top</b></a>)</div>\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = train\n",
    "df['text'] = df['text'].str.lower()   # pasamos a lowercase\n",
    "df = df.drop(['id', 'location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>quarantine</td>\n",
       "      <td>reddit updates content policy promises to quar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>twister</td>\n",
       "      <td>crazy mom threw teen daughter a nude twister s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>electrocute</td>\n",
       "      <td>kayla is about to electrocute herself.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>evacuation</td>\n",
       "      <td>gas leak forces evacuation in east saint john ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>bombed</td>\n",
       "      <td>@christopherszen @hunterlove1995 @tblack yeah ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>collapse</td>\n",
       "      <td>warne ponting shocked by australian collapse -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>tragedy</td>\n",
       "      <td>there is no greater tragedy than becoming comf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7459</th>\n",
       "      <td>wounds</td>\n",
       "      <td>court back in session. testimony continues wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword                                               text  target\n",
       "5468   quarantine  reddit updates content policy promises to quar...       0\n",
       "6997      twister  crazy mom threw teen daughter a nude twister s...       1\n",
       "3089  electrocute             kayla is about to electrocute herself.       0\n",
       "3396   evacuation  gas leak forces evacuation in east saint john ...       1\n",
       "1113       bombed  @christopherszen @hunterlove1995 @tblack yeah ...       0\n",
       "1600     collapse  warne ponting shocked by australian collapse -...       0\n",
       "6779      tragedy  there is no greater tragedy than becoming comf...       0\n",
       "7459       wounds  court back in session. testimony continues wit...       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generamos nuevas features sobre el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos una columna que indica la cantidad de links a  enlaces externos\n",
    "df['link'] = df['text'].apply(lambda x: x.count('http'))\n",
    "\n",
    "# generamos una columna que indica la cantidad de referencias a otras cuentas de twitter\n",
    "df['contact'] = df['text'].apply(lambda x: x.count('@'))\n",
    "\n",
    "# generamos una columna que indica la cantidad de hashtags\n",
    "df['hashtag'] = df['text'].apply(lambda x: x.count('#'))\n",
    "\n",
    "# generamos una columna que indica la cantidad de digitos\n",
    "df['numerics'] = df['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "# calculamos la longitud del tweet andes de limpiar\n",
    "df['length'] = df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos la cantidad de palabras antes de limpiar\n",
    "def count_words(text):\n",
    "    '''\n",
    "    Funcion que toma un texto y devuelve la cantidad de palabras\n",
    "    '''\n",
    "    word_counts = len(text.split(' '))\n",
    "    return word_counts\n",
    "\n",
    "df['words'] = df['text'].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpiamos el texto eliminando urls, cuentas, hashtags y numeros\n",
    "\n",
    "def clean_str(string):\n",
    "    string = re.sub(r'https?\\://\\S+', '', string)\n",
    "    string = re.sub(r'http?\\://\\S+', '', string)\n",
    "    string = re.sub(r'@\\w*\\s', '', string)\n",
    "    string = re.sub(r'#\\w*\\s', '', string)\n",
    "    string = re.sub(r'\\d', '', string)\n",
    "    return string\n",
    "\n",
    "df['text_clean'] = df['text'].apply(lambda x: clean_str(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>link</th>\n",
       "      <th>contact</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>numerics</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>volcano</td>\n",
       "      <td>this la startup is so hot that their flowers c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>17</td>\n",
       "      <td>this la startup is so hot that their flowers c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7386</th>\n",
       "      <td>windstorm</td>\n",
       "      <td>new roof and hardy up..windstorm inspection to...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "      <td>new roof and hardy up..windstorm inspection to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>traumatised</td>\n",
       "      <td>@disneyirh so traumatised im ???? http://t.co/...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>so traumatised im ????</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>collide</td>\n",
       "      <td>@mattcohen4fake gamma ray january worlds colli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>22</td>\n",
       "      <td>gamma ray january worlds collide she waits be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>fire</td>\n",
       "      <td>my asshole is on fire  https://t.co/y3fo0ghg8t</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>my asshole is on fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword                                               text  target  \\\n",
       "7152      volcano  this la startup is so hot that their flowers c...       0   \n",
       "7386    windstorm  new roof and hardy up..windstorm inspection to...       0   \n",
       "6894  traumatised  @disneyirh so traumatised im ???? http://t.co/...       1   \n",
       "1682      collide  @mattcohen4fake gamma ray january worlds colli...       0   \n",
       "3745         fire     my asshole is on fire  https://t.co/y3fo0ghg8t       0   \n",
       "\n",
       "      link  contact  hashtag  numerics  length  words  \\\n",
       "7152     1        1        0         0     113     17   \n",
       "7386     1        0        0         0      75      8   \n",
       "6894     1        1        0         0      56      6   \n",
       "1682     0        1        0         0     129     22   \n",
       "3745     1        0        0         0      46      7   \n",
       "\n",
       "                                             text_clean  \n",
       "7152  this la startup is so hot that their flowers c...  \n",
       "7386  new roof and hardy up..windstorm inspection to...  \n",
       "6894                            so traumatised im ????   \n",
       "1682  gamma ray january worlds collide she waits be ...  \n",
       "3745                            my asshole is on fire    "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "<a id='section4'></a>\n",
    "\n",
    "<div style=\"border-bottom:3px solid #000;\"> \n",
    "<div align=\"left\"><h2>Step 4: NLP</h2></div>\n",
    "<div align=\"right\">(return to <a href='#top1'><b>Top</b></a>)</div>\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos signos de puntuacion y caracteres especiales\n",
    "df['text_clean'] = df['text_clean'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_tokenize'] = df['text_clean'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unificamos palabras que poseen la misma raiz aplicando la funcion word_lematizer\n",
    "df['word_lemmatizer'] = df['word_tokenize'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unificamos la lista de tokens para poder analizar el texto limpio\n",
    "df['text_clean'] = df['word_lemmatizer'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos nuevamente la longuitud, pero ahora del texto limpio                       \n",
    "df['length-clean'] = df['text_clean'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_clean'] = df['text_clean'].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 150)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>another mac vuln!\\n\\nhttps://t.co/oxxrnab8un</td>\n",
       "      <td>another mac vuln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>#3: titan warriorcord 100 feet - authentic military 550 paracord - mil-c-5040-h type iii 7 strand 5/16' di... http://t.co/eejrmktj0r</td>\n",
       "      <td>titan warriorcord foot authentic military paracord milch type iii strand di</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>@untameddirewolf 'i... wow. alright.' sansa shook her head and blinked rapidly as the new information sunk in. 'i really don't know what--</td>\n",
       "      <td>i wow alright sansa shook head blinked rapidly new information sunk in i really know what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>remembrance  http://t.co/ii4ewe1qir #hiroshima http://t.co/h3vusqzyqo</td>\n",
       "      <td>remembrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>womens handbags cross body geometric pattern satchel totes shoulder bags white http://t.co/l1gfxgozvx http://t.co/tkjybjjskl</td>\n",
       "      <td>woman handbag cross body geometric pattern satchel tote shoulder bag white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>west valley i405 n / us101 s i405 n con **trfc collision-unkn inj** http://t.co/js9ehp88wq</td>\n",
       "      <td>west valley n u n con trfc collisionunkn inj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>update on pulwama encounter that began earlier today: 2nd terrorist killed by security forces. security forces...  http://t.co/m5rjekvddp</td>\n",
       "      <td>update pulwama encounter began earlier today nd terrorist killed security force security force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>4yygb mhtw4fnet\\n\\nthousands evacuated as taiwan prepares for strongest typhoon of 2015 - abc online</td>\n",
       "      <td>yygb mhtwfnet thousand evacuated taiwan prepares strongest typhoon abc online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>the latest: more homes razed by northern california wildfire - abc news http://t.co/ymy4rskq3d</td>\n",
       "      <td>latest home razed northern california wildfire abc news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>heart disease prevention: what about secondhand smoke? http://t.co/ydgmgbryl2</td>\n",
       "      <td>heart disease prevention secondhand smoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            text  \\\n",
       "4343                                                                                                another mac vuln!\\n\\nhttps://t.co/oxxrnab8un   \n",
       "4976        #3: titan warriorcord 100 feet - authentic military 550 paracord - mil-c-5040-h type iii 7 strand 5/16' di... http://t.co/eejrmktj0r   \n",
       "6478  @untameddirewolf 'i... wow. alright.' sansa shook her head and blinked rapidly as the new information sunk in. 'i really don't know what--   \n",
       "6593                                                                       remembrance  http://t.co/ii4ewe1qir #hiroshima http://t.co/h3vusqzyqo   \n",
       "1053                womens handbags cross body geometric pattern satchel totes shoulder bags white http://t.co/l1gfxgozvx http://t.co/tkjybjjskl   \n",
       "1762                                                  west valley i405 n / us101 s i405 n con **trfc collision-unkn inj** http://t.co/js9ehp88wq   \n",
       "6633   update on pulwama encounter that began earlier today: 2nd terrorist killed by security forces. security forces...  http://t.co/m5rjekvddp   \n",
       "7049                                        4yygb mhtw4fnet\\n\\nthousands evacuated as taiwan prepares for strongest typhoon of 2015 - abc online   \n",
       "7612                                              the latest: more homes razed by northern california wildfire - abc news http://t.co/ymy4rskq3d   \n",
       "477                                                                heart disease prevention: what about secondhand smoke? http://t.co/ydgmgbryl2   \n",
       "\n",
       "                                                                                          text_clean  \n",
       "4343                                                                                another mac vuln  \n",
       "4976                     titan warriorcord foot authentic military paracord milch type iii strand di  \n",
       "6478       i wow alright sansa shook head blinked rapidly new information sunk in i really know what  \n",
       "6593                                                                                     remembrance  \n",
       "1053                      woman handbag cross body geometric pattern satchel tote shoulder bag white  \n",
       "1762                                                    west valley n u n con trfc collisionunkn inj  \n",
       "6633  update pulwama encounter began earlier today nd terrorist killed security force security force  \n",
       "7049                   yygb mhtwfnet thousand evacuated taiwan prepares strongest typhoon abc online  \n",
       "7612                                         latest home razed northern california wildfire abc news  \n",
       "477                                                        heart disease prevention secondhand smoke  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'text_clean']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword'] = df.keyword.str.replace('%20', '_')\n",
    "df['keyword'] = df.keyword.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>link</th>\n",
       "      <th>contact</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>numerics</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>word_lemmatizer</th>\n",
       "      <th>length-clean</th>\n",
       "      <th>words_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>nuclear_reactor</td>\n",
       "      <td>a 17 year boy scout created a mini nuclear reactor in his home</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>year boy scout created mini nuclear reactor home</td>\n",
       "      <td>[year, boy, scout, created, mini, nuclear, reactor, home]</td>\n",
       "      <td>[year, boy, scout, created, mini, nuclear, reactor, home]</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>collapsed</td>\n",
       "      <td>petition | heartless owner that whipped horse until it collapsed is told he can keep his animal! act now! http://t.co/njrjxqbjr4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>petition heartless owner whipped horse collapsed told keep animal act now</td>\n",
       "      <td>[petition, heartless, owner, whipped, horse, collapsed, told, keep, animal, act, now]</td>\n",
       "      <td>[petition, heartless, owner, whipped, horse, collapsed, told, keep, animal, act, now]</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>collapsed</td>\n",
       "      <td>@indiepopmom i cant breathe my lungs collapsed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>cant breathe lung collapsed</td>\n",
       "      <td>[cant, breathe, lungs, collapsed]</td>\n",
       "      <td>[cant, breathe, lung, collapsed]</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              keyword  \\\n",
       "5150  nuclear_reactor   \n",
       "1648        collapsed   \n",
       "1643        collapsed   \n",
       "\n",
       "                                                                                                                                  text  \\\n",
       "5150                                                                    a 17 year boy scout created a mini nuclear reactor in his home   \n",
       "1648  petition | heartless owner that whipped horse until it collapsed is told he can keep his animal! act now! http://t.co/njrjxqbjr4   \n",
       "1643                                                                                    @indiepopmom i cant breathe my lungs collapsed   \n",
       "\n",
       "      target  link  contact  hashtag  numerics  length  words  \\\n",
       "5150       0     0        0        0         1      62     13   \n",
       "1648       0     1        0        0         0     128     20   \n",
       "1643       0     0        1        0         0      46      7   \n",
       "\n",
       "                                                                     text_clean  \\\n",
       "5150                           year boy scout created mini nuclear reactor home   \n",
       "1648  petition heartless owner whipped horse collapsed told keep animal act now   \n",
       "1643                                                cant breathe lung collapsed   \n",
       "\n",
       "                                                                              word_tokenize  \\\n",
       "5150                              [year, boy, scout, created, mini, nuclear, reactor, home]   \n",
       "1648  [petition, heartless, owner, whipped, horse, collapsed, told, keep, animal, act, now]   \n",
       "1643                                                      [cant, breathe, lungs, collapsed]   \n",
       "\n",
       "                                                                            word_lemmatizer  \\\n",
       "5150                              [year, boy, scout, created, mini, nuclear, reactor, home]   \n",
       "1648  [petition, heartless, owner, whipped, horse, collapsed, told, keep, animal, act, now]   \n",
       "1643                                                       [cant, breathe, lung, collapsed]   \n",
       "\n",
       "      length-clean  words_clean  \n",
       "5150            48            8  \n",
       "1648            73           11  \n",
       "1643            27            4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF- IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicamos TF-IDF seteando un maximo de 1500 palabras\n",
    "tfidf = TfidfVectorizer(max_features=1500, lowercase=True, analyzer='word', stop_words= 'english',ngram_range=(1,1))\n",
    "\n",
    "\n",
    "train_vect = tfidf.fit_transform(df['text_clean'])                                             \n",
    "\n",
    "# lo pasamos a dataframe\n",
    "df_tf_idf = pd.DataFrame(data = train_vect.todense(), columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 1500)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000    7602\n",
       "0.750117       3\n",
       "0.317217       1\n",
       "0.769954       1\n",
       "0.758087       1\n",
       "0.322396       1\n",
       "0.601328       1\n",
       "0.513594       1\n",
       "0.493300       1\n",
       "0.437970       1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "      <th>û_</th>\n",
       "      <th>ûïwhen</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûó</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  abandoned  abc  ablaze  able  absolutely  access  accident  according  \\\n",
       "0  0.0        0.0  0.0     0.0   0.0         0.0     0.0       0.0        0.0   \n",
       "1  0.0        0.0  0.0     0.0   0.0         0.0     0.0       0.0        0.0   \n",
       "2  0.0        0.0  0.0     0.0   0.0         0.0     0.0       0.0        0.0   \n",
       "3  0.0        0.0  0.0     0.0   0.0         0.0     0.0       0.0        0.0   \n",
       "4  0.0        0.0  0.0     0.0   0.0         0.0     0.0       0.0        0.0   \n",
       "\n",
       "   account  ...  york  young  youth  youtube   yr  zone   û_  ûïwhen   ûò   ûó  \n",
       "0      0.0  ...   0.0    0.0    0.0      0.0  0.0   0.0  0.0     0.0  0.0  0.0  \n",
       "1      0.0  ...   0.0    0.0    0.0      0.0  0.0   0.0  0.0     0.0  0.0  0.0  \n",
       "2      0.0  ...   0.0    0.0    0.0      0.0  0.0   0.0  0.0     0.0  0.0  0.0  \n",
       "3      0.0  ...   0.0    0.0    0.0      0.0  0.0   0.0  0.0     0.0  0.0  0.0  \n",
       "4      0.0  ...   0.0    0.0    0.0      0.0  0.0   0.0  0.0     0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 1500 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como existe la columna target en el analisis tf-idf, la modifico para hacer el concat con 'target' y que no se duplique\n",
    "df_tf_idf['targ'] = df_tf_idf['target']\n",
    "df_tf_idf = df_tf_idf.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para no perder tantos registros, vamos a dejar de lado por ahora la columna ``keyword`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()  # chequeamos si los labels estan balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos col que contienen texto y conservamos unicamente las numericas\n",
    "df_num = df.drop([ 'keyword', 'text', 'text_clean', 'word_tokenize', 'word_lemmatizer'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_num, df_tf_idf], axis=1)  # revisar porque aparecen dos columnas llamadas target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 1509)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separamos el target del resto de los features\n",
    "\n",
    "y = df_train.target    \n",
    "X = df_train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 1508), (7613,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5329, 1508), (2284, 1508), (5329,), (2284,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacemos division entre train y test para cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)      \n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estandarizamos las features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos una Crossval\n",
    "cv = StratifiedKFold(n_splits=5, random_state=27, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': [0.1,0.2, 0.3, 0.4],\n",
    "    'num_leaves':[10, 15, 20],\n",
    "    'max_depth':[ 18, 20, 25, 30], \n",
    "    'n_estimators': [100, 130, 150]  \n",
    "    }\n",
    "\n",
    "model_lgbm=lgbm.LGBMClassifier(n_jobs=-1, random_state=27,  boosting_type='gbdt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm_cv = RandomizedSearchCV(model_lgbm, params, cv=cv, n_iter=25, verbose=False, scoring='accuracy', random_state=27)\n",
    "                                                                                          # 'neg_log_loss'\n",
    "lgbm_cls = lgbm_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 10, 'n_estimators': 130, 'max_depth': 20, 'learning_rate': 0.3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_cls.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7692644483362522\n"
     ]
    }
   ],
   "source": [
    "pred_search = lgbm_cv.predict(X_test)\n",
    "print(accuracy_score(y_test, pred_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7661996497373029"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7661996497373029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7653239929947461"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7653239929947461"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
