{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP-2 Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oh La La... Data!\n",
    "\n",
    "* **Hamma AALI CHTOUKI** --- *Padrón 106607 - Alumno regular de intercambio.*  \n",
    "* **Aymeryc COUSAERT** ------  *Padrón 105464 - Alumno regular de intercambio.*\n",
    "* **Mariana VINYOLAS**  ---------  *Alumna oyente.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3aDXdkY2bsU"
   },
   "source": [
    "<!-- ![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "<a id='section2'></a>\n",
    "\n",
    "<div style=\"border-bottom:3px solid #000;\"> \n",
    "<div align=\"left\"><h2>Step 2: Import de librerias </h2></div>\n",
    "<div align=\"right\">(return to <a href='#top1'><b>Top</b></a>)</div>\n",
    "</div> -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import scikitplot as skplt\n",
    "from scikitplot.metrics import plot_roc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Smnr3pgkKld_"
   },
   "source": [
    "<!-- ![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "<a id='section3'></a>\n",
    "\n",
    "<div style=\"border-bottom:3px solid #000;\"> \n",
    "<div align=\"left\"><h2>Step 3: Feature engineering</h2></div>\n",
    "<div align=\"right\">(return to <a href='#top1'><b>Top</b></a>)</div>\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = train\n",
    "df['text'] = df['text'].str.lower()   # pasamos a lowercase\n",
    "df = df.drop(['id', 'location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>flames</td>\n",
       "      <td>*new* snap on tools black baseball hat/cap sil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>bioterror</td>\n",
       "      <td>fedex no longer to transport bioterror germs i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>outbreak</td>\n",
       "      <td>new york city outbreak: what is legionnaire's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>mudslide</td>\n",
       "      <td>'it looks like a mudslide' 'it's like chewing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>flood</td>\n",
       "      <td>spot flood combo 53inch 300w curved cree led w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6426</th>\n",
       "      <td>suicide%20bomber</td>\n",
       "      <td>#?? #?? #??? #??? suicide bomber kills 15 in s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>rioting</td>\n",
       "      <td>`bbcnews the ass. of british insurers says rio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>drowning</td>\n",
       "      <td>@homukami only urs and srs matter rs you'll be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword                                               text  \\\n",
       "3852            flames  *new* snap on tools black baseball hat/cap sil...   \n",
       "588          bioterror  fedex no longer to transport bioterror germs i...   \n",
       "5301          outbreak  new york city outbreak: what is legionnaire's ...   \n",
       "5016          mudslide  'it looks like a mudslide' 'it's like chewing ...   \n",
       "3914             flood  spot flood combo 53inch 300w curved cree led w...   \n",
       "6426  suicide%20bomber  #?? #?? #??? #??? suicide bomber kills 15 in s...   \n",
       "5790           rioting  `bbcnews the ass. of british insurers says rio...   \n",
       "2988          drowning  @homukami only urs and srs matter rs you'll be...   \n",
       "\n",
       "      target  \n",
       "3852       0  \n",
       "588        1  \n",
       "5301       1  \n",
       "5016       0  \n",
       "3914       0  \n",
       "6426       1  \n",
       "5790       1  \n",
       "2988       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generamos nuevas features sobre el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos una columna que indica la cantidad de links a  enlaces externos\n",
    "df['link'] = df['text'].apply(lambda x: x.count('http'))\n",
    "\n",
    "# generamos una columna que indica la cantidad de referencias a otras cuentas de twitter\n",
    "df['contact'] = df['text'].apply(lambda x: x.count('@'))\n",
    "\n",
    "# generamos una columna que indica la cantidad de hashtags\n",
    "df['hashtag'] = df['text'].apply(lambda x: x.count('#'))\n",
    "\n",
    "# generamos una columna que indica la cantidad de digitos\n",
    "df['numerics'] = df['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "# calculamos la longitud del tweet andes de limpiar\n",
    "df['length'] = df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos la cantidad de palabras antes de limpiar\n",
    "def count_words(text):\n",
    "    '''\n",
    "    Funcion que toma un texto y devuelve la cantidad de palabras\n",
    "    '''\n",
    "    word_counts = len(text.split(' '))\n",
    "    return word_counts\n",
    "\n",
    "df['words'] = df['text'].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpiamos el texto eliminando urls, cuentas, hashtags y numeros\n",
    "\n",
    "def clean_str(string):\n",
    "    string = re.sub(r'https?\\://\\S+', '', string)\n",
    "    string = re.sub(r'http?\\://\\S+', '', string)\n",
    "    string = re.sub(r'@\\w*\\s', '', string)\n",
    "    string = re.sub(r'#\\w*\\s', '', string)\n",
    "    string = re.sub(r'\\d', '', string)\n",
    "    return string\n",
    "\n",
    "df['text_clean'] = df['text'].apply(lambda x: clean_str(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>link</th>\n",
       "      <th>contact</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>numerics</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>crashed</td>\n",
       "      <td>pakistan says army helicopter has crashed in c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>15</td>\n",
       "      <td>pakistan says army helicopter has crashed in c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>casualty</td>\n",
       "      <td>#nowplaying: dubstep hardstyle trap messy mix ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>15</td>\n",
       "      <td>#nowplaying: dubstep hardstyle trap messy mix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>destroyed</td>\n",
       "      <td>black eye 9: a space battle occurred at star o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>19</td>\n",
       "      <td>black eye : a space battle occurred at star o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>deluge</td>\n",
       "      <td>it's a deluge in trois-rivieres. about one hou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>13</td>\n",
       "      <td>it's a deluge in trois-rivieres. about one hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>tsunami</td>\n",
       "      <td>@greenlacey godslove &amp;amp; #thanku my sister f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>19</td>\n",
       "      <td>godslove &amp;amp; my sister for rt of new video  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        keyword                                               text  target  \\\n",
       "1829    crashed  pakistan says army helicopter has crashed in c...       1   \n",
       "1458   casualty  #nowplaying: dubstep hardstyle trap messy mix ...       1   \n",
       "2611  destroyed  black eye 9: a space battle occurred at star o...       0   \n",
       "2213     deluge  it's a deluge in trois-rivieres. about one hou...       0   \n",
       "6974    tsunami  @greenlacey godslove &amp; #thanku my sister f...       0   \n",
       "\n",
       "      link  contact  hashtag  numerics  length  words  \\\n",
       "1829     1        0        0         1     114     15   \n",
       "1458     2        1        1         0     138     15   \n",
       "2611     0        0        0         3     106     19   \n",
       "2213     1        0        1         0     102     13   \n",
       "6974     1        1        1         0     138     19   \n",
       "\n",
       "                                             text_clean  \n",
       "1829  pakistan says army helicopter has crashed in c...  \n",
       "1458  #nowplaying: dubstep hardstyle trap messy mix ...  \n",
       "2611  black eye : a space battle occurred at star o ...  \n",
       "2213  it's a deluge in trois-rivieres. about one hou...  \n",
       "6974  godslove &amp; my sister for rt of new video  ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "<a id='section4'></a>\n",
    "\n",
    "<div style=\"border-bottom:3px solid #000;\"> \n",
    "<div align=\"left\"><h2>Step 4: NLP</h2></div>\n",
    "<div align=\"right\">(return to <a href='#top1'><b>Top</b></a>)</div>\n",
    "</div> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos signos de puntuacion y caracteres especiales\n",
    "df['text_clean'] = df['text_clean'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_tokenize'] = df['text_clean'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unificamos palabras que poseen la misma raiz aplicando la funcion word_lematizer\n",
    "df['word_lemmatizer'] = df['word_tokenize'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unificamos la lista de tokens para poder analizar el texto limpio\n",
    "df['text_clean'] = df['word_lemmatizer'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos nuevamente la longuitud, pero ahora del texto limpio                       \n",
    "df['length-clean'] = df['text_clean'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_clean'] = df['text_clean'].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 150)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>going to redo my nails and watch behind the scenes of desolation of smaug ayyy</td>\n",
       "      <td>going redo nail watch behind scene desolation smaug ayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>@justinejayyy ohgod xd i didn't mean it so =p but you have that fire truck in the back of you to make up for it so you good xd</td>\n",
       "      <td>ohgod xd mean p fire truck back make good xd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6860</th>\n",
       "      <td>@thetimepast @saalon i have childhood trauma more resolved than theirs. actual trauma. fricken babies.</td>\n",
       "      <td>childhood trauma resolved theirs actual trauma fricken baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>thank you so so much to everyone for posting the rain and hail outside ... i had no idea guys ????????</td>\n",
       "      <td>thank much everyone posting rain hail outside idea guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>#hot  c-130 specially modified to land in a stadium and rescue hostages in iran in 1980 http://t.co/w0exzad5gc #prebreak #best</td>\n",
       "      <td>c specially modified land stadium rescue hostage iran best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>tips so that finding the customers ego drought: dqsvyusy</td>\n",
       "      <td>tip finding customer ego drought dqsvyusy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>@aminespn mencius tears are worse correct? takes the explosion n more pain day to day right?</td>\n",
       "      <td>mencius tear worse correct take explosion n pain day day right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>you can't fight fate and you can't survive alone... i can't help but notice that almost seems like a definition of who i am...</td>\n",
       "      <td>cant fight fate cant survive alone cant help notice almost seems like definition am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>@sapphirescallop destroy oppa image? oops! there's nothing left right? haaaaaa</td>\n",
       "      <td>destroy oppa image oops there nothing left right haaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>i hope they fall off a cliff.</td>\n",
       "      <td>hope fall cliff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                text  \\\n",
       "2522                                                  going to redo my nails and watch behind the scenes of desolation of smaug ayyy   \n",
       "3792  @justinejayyy ohgod xd i didn't mean it so =p but you have that fire truck in the back of you to make up for it so you good xd   \n",
       "6860                          @thetimepast @saalon i have childhood trauma more resolved than theirs. actual trauma. fricken babies.   \n",
       "4079                          thank you so so much to everyone for posting the rain and hail outside ... i had no idea guys ????????   \n",
       "4462  #hot  c-130 specially modified to land in a stadium and rescue hostages in iran in 1980 http://t.co/w0exzad5gc #prebreak #best   \n",
       "2866                                                                        tips so that finding the customers ego drought: dqsvyusy   \n",
       "3487                                    @aminespn mencius tears are worse correct? takes the explosion n more pain day to day right?   \n",
       "6523  you can't fight fate and you can't survive alone... i can't help but notice that almost seems like a definition of who i am...   \n",
       "2575                                                  @sapphirescallop destroy oppa image? oops! there's nothing left right? haaaaaa   \n",
       "1576                                                                                                   i hope they fall off a cliff.   \n",
       "\n",
       "                                                                               text_clean  \n",
       "2522                             going redo nail watch behind scene desolation smaug ayyy  \n",
       "3792                                         ohgod xd mean p fire truck back make good xd  \n",
       "6860                          childhood trauma resolved theirs actual trauma fricken baby  \n",
       "4079                               thank much everyone posting rain hail outside idea guy  \n",
       "4462                           c specially modified land stadium rescue hostage iran best  \n",
       "2866                                            tip finding customer ego drought dqsvyusy  \n",
       "3487                       mencius tear worse correct take explosion n pain day day right  \n",
       "6523  cant fight fate cant survive alone cant help notice almost seems like definition am  \n",
       "2575                             destroy oppa image oops there nothing left right haaaaaa  \n",
       "1576                                                                      hope fall cliff  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'text_clean']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword'] = df.keyword.str.replace('%20', '_')\n",
    "df['keyword'] = df.keyword.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>link</th>\n",
       "      <th>contact</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>numerics</th>\n",
       "      <th>length</th>\n",
       "      <th>words</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>word_tokenize</th>\n",
       "      <th>word_lemmatizer</th>\n",
       "      <th>length-clean</th>\n",
       "      <th>words_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>mass_murderer</td>\n",
       "      <td>not only are you a mass murderer but at a movie theatre where niggas dropped bread to see a movie? cmon man.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>22</td>\n",
       "      <td>mass murderer movie theatre nigga dropped bread see movie cmon man</td>\n",
       "      <td>[mass, murderer, movie, theatre, niggas, dropped, bread, see, movie, cmon, man]</td>\n",
       "      <td>[mass, murderer, movie, theatre, nigga, dropped, bread, see, movie, cmon, man]</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>hazard</td>\n",
       "      <td>battlefield 4 funny moments - dukes of hazard undercover soldier mav t... https://t.co/ju8nfpnedl via @youtube</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>15</td>\n",
       "      <td>battlefield funny moment duke hazard undercover soldier mav t via youtube</td>\n",
       "      <td>[battlefield, funny, moments, dukes, hazard, undercover, soldier, mav, t, via, youtube]</td>\n",
       "      <td>[battlefield, funny, moment, duke, hazard, undercover, soldier, mav, t, via, youtube]</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>survive</td>\n",
       "      <td>hank williams jr. - 'country boys can survive' (official music video) https://t.co/you7wn9xvs via @youtube</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>14</td>\n",
       "      <td>hank williams jr country boy survive official music video via youtube</td>\n",
       "      <td>[hank, williams, jr, country, boys, survive, official, music, video, via, youtube]</td>\n",
       "      <td>[hank, williams, jr, country, boy, survive, official, music, video, via, youtube]</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            keyword  \\\n",
       "4872  mass_murderer   \n",
       "4207         hazard   \n",
       "6499        survive   \n",
       "\n",
       "                                                                                                                text  \\\n",
       "4872    not only are you a mass murderer but at a movie theatre where niggas dropped bread to see a movie? cmon man.   \n",
       "4207  battlefield 4 funny moments - dukes of hazard undercover soldier mav t... https://t.co/ju8nfpnedl via @youtube   \n",
       "6499      hank williams jr. - 'country boys can survive' (official music video) https://t.co/you7wn9xvs via @youtube   \n",
       "\n",
       "      target  link  contact  hashtag  numerics  length  words  \\\n",
       "4872       0     0        0        0         0     108     22   \n",
       "4207       0     1        1        0         1     110     15   \n",
       "6499       0     1        1        0         0     106     14   \n",
       "\n",
       "                                                                     text_clean  \\\n",
       "4872         mass murderer movie theatre nigga dropped bread see movie cmon man   \n",
       "4207  battlefield funny moment duke hazard undercover soldier mav t via youtube   \n",
       "6499      hank williams jr country boy survive official music video via youtube   \n",
       "\n",
       "                                                                                word_tokenize  \\\n",
       "4872          [mass, murderer, movie, theatre, niggas, dropped, bread, see, movie, cmon, man]   \n",
       "4207  [battlefield, funny, moments, dukes, hazard, undercover, soldier, mav, t, via, youtube]   \n",
       "6499       [hank, williams, jr, country, boys, survive, official, music, video, via, youtube]   \n",
       "\n",
       "                                                                            word_lemmatizer  \\\n",
       "4872         [mass, murderer, movie, theatre, nigga, dropped, bread, see, movie, cmon, man]   \n",
       "4207  [battlefield, funny, moment, duke, hazard, undercover, soldier, mav, t, via, youtube]   \n",
       "6499      [hank, williams, jr, country, boy, survive, official, music, video, via, youtube]   \n",
       "\n",
       "      length-clean  words_clean  \n",
       "4872            66           11  \n",
       "4207            73           11  \n",
       "6499            69           11  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()  # chequeamos si los labels estan balanceados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos col que contienen texto y conservamos unicamente las numericas\n",
    "df_num = df.drop([ 'keyword', 'text', 'text_clean', 'word_tokenize', 'word_lemmatizer'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separamos el target del resto de los features\n",
    "\n",
    "y = df_num.target    \n",
    "X = df_num.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 8), (7613,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5329, 8), (2284, 8), (5329,), (2284,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacemos division entre train y test para cross validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)      \n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth= 4, random_state=27)\n",
    "y_pred = rf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6637267780071308, 0.6598073555166375)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train), rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un score tan bajo probamos hacer un GridSearch para correr el modelo con mejores parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos cross validation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=27, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [ 200, 250, 300], \n",
    "              'max_features': [1, 2, 3], \n",
    "              'max_depth': [ 10, 20, 30], \n",
    "              'min_samples_leaf':[5, 10, 20]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=0), param_grid=param_grid,\n",
    "                              cv=cv, verbose=1, n_jobs=-1, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=27, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=0,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30], 'max_features': [1, 2, 3],\n",
       "                         'min_samples_leaf': [5, 10, 20],\n",
       "                         'n_estimators': [200, 250, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_grid_search.fit(X_train, y_train)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 5,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_grid = rf_grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7967723775567649, 0.6843257443082311)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.score(X_train, y_train), rf_grid_search.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6843257443082311\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, pred_grid))   # sacando TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6554290718038529"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6554290718038529  # con TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
